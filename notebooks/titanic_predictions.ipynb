{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbasecondab0e06224b0a74485a055e5087d3fc751",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "2fd127e1b1222c75630ed5cdd42c40bf2ae003092f8ef1d43b1a03fa3691fe3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Titanic predictions\n",
    "This notebook gives an example application of the decision tree classifier. The titanic dataset documents a number of attributes related to passengers of the famous Titanic voyage. We will try to use these attributes to predict whether a passenger died or survived from the titanic dataset.\n",
    "\n",
    "Dataset can be donwloaded from [here](https://www.kaggle.com/c/titanic/data).\n",
    "\n",
    "We will also compare the performance of our implementation of a decision tree classifier to an open-source implementation from sci-kit learn."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "## Calling C++ directly from Python\n",
    "Compiled C and C++ libraries can be directly interfaced and called from Python. The cell below interfaces our C++ decision tree classifier into Python so we can call it directly from this notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create wrapper to call C++ library directly from Python\n",
    "import ctypes\n",
    "import pathlib\n",
    "\n",
    "def cpp_decision_tree(trainPath, testPath):\n",
    "    # Load the shared library into ctypes\n",
    "    libname = pathlib.Path().absolute() / \"../build/libDecisionTree.dylib\"\n",
    "\n",
    "    c_lib = ctypes.CDLL(libname)\n",
    "    decisionTree = c_lib.decisionTree\n",
    "    decisionTree.restype = ctypes.POINTER(ctypes.c_int)\n",
    "    decisionTree.argtypes = [ctypes.c_char_p, ctypes.c_char_p]\n",
    "\n",
    "\n",
    "    with open(testPath) as f:\n",
    "        first_line = f.readline()\n",
    "    number_predictions = first_line.count(',') + 1\n",
    "    \n",
    "    decisionTreeP = decisionTree(trainPath.encode('utf-8'), testPath.encode('utf-8'))\n",
    "\n",
    "    predictions = [decisionTreeP[i] for i in range(number_predictions)]\n",
    "    return predictions"
   ]
  },
  {
   "source": [
    "## Preparing dataset for training classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('titanic/train.csv')"
   ]
  },
  {
   "source": [
    "As the decision tree classifier was only implemented to handle categorical features, we select only the categorical features from our dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\n",
    "target_variable = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to categorical types\n",
    "train = train[categorical_features + [target_variable]].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Embarked = train.Embarked.cat.add_categories(\"NaN\").fillna(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc = train.copy()"
   ]
  },
  {
   "source": [
    "We numerically encode our categories to integers to be compatible with the C++ library implementation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.Pclass.cat.codes\n",
    "for col in train_enc.columns:\n",
    "    train_enc[col] = train_enc[col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Int64Index([1, 2, 3], dtype='int64')\nIndex(['female', 'male'], dtype='object')\nInt64Index([0, 1, 2, 3, 4, 5, 8], dtype='int64')\nInt64Index([0, 1, 2, 3, 4, 5, 6], dtype='int64')\nIndex(['C', 'Q', 'S', 'NaN'], dtype='object')\nInt64Index([0, 1], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "for col in train.columns:\n",
    "    print(train[col].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2 0 1]\n[1 0]\n[1 0 3 4 2 5 6]\n[0 1 2 5 3 4 6]\n[2 0 1 3]\n[0 1]\n"
     ]
    }
   ],
   "source": [
    "# check category labels are compatible with C++ library\n",
    "for col in train_enc.columns:\n",
    "    print(train_enc[col].unique())"
   ]
  },
  {
   "source": [
    "Split data into train and test sets to enable evaluation of model against true values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(train_enc, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to transpose to be compatible with C++ library\n",
    "X_train.T.to_csv(\"../test/resources/titanicTrain.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outcomes from test\n",
    "X_test.drop(columns='Survived').T.to_csv(\"../test/resources/titanicTest.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "862    1\n",
       "223    0\n",
       "84     1\n",
       "680    0\n",
       "535    1\n",
       "      ..\n",
       "506    1\n",
       "467    0\n",
       "740    1\n",
       "354    0\n",
       "449    1\n",
       "Name: Survived, Length: 223, dtype: int8"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "X_test.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data csvs into C++ library and return predictions\n",
    "predictions = cpp_decision_tree(\"../test/resources/titanicTrain.csv\", \"../test/resources/titanicTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[106,  22],\n",
       "       [ 44,  51]])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "confusion_matrix(X_test.Survived, predictions)"
   ]
  },
  {
   "source": [
    "## Compare with open-source decision tree implementation\n",
    "Compare to scikit-learn decision tree classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare using sklearn decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train.drop(columns='Survived'), X_train.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_predictions = clf.predict(X_test.drop(columns='Survived'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[119,   9],\n",
       "       [ 43,  52]])"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "confusion_matrix(X_test.Survived, sklearn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean absolute error between C++ implementation of classifier and SK-learn\n",
    "MAE = np.sum(np.abs(sklearn_predictions - predictions)) / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.14349775784753363"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "MAE"
   ]
  },
  {
   "source": [
    "## Results\n",
    "We see 0.14 mean absolute error between the scikit-learn implementation and our own C++ implementation. We would expect the default settings for the SK-learn classifier to give the same results as our implementation of the classifier on this dataset, so likely there are some bugs in our implementation or we are misinterpreting the SK-learn docs. We aren't too far off with 85% of predictions from each classifier giving the same label."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}